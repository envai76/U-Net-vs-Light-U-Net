{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be49f79b-442c-4509-912e-de320713eee3",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4badf27c-abfc-4189-a445-b5de4bedd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pingouin\n",
    "# !pip install openpyxl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from statsmodels.stats.weightstats import DescrStatsW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9892562-4780-46aa-b8a7-bc32d77e149a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375cab04-f8a8-4538-88ce-bc5f107eb5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC      F  df1  df2          pval  \\\n",
      "0   ICC1   Single raters absolute  0.991607  473.6    2    9  7.614159e-10   \n",
      "1   ICC2     Single random raters  0.991611  592.0    2    6  1.281778e-07   \n",
      "2   ICC3      Single fixed raters  0.993277  592.0    2    6  1.281778e-07   \n",
      "3  ICC1k  Average raters absolute  0.997889  473.6    2    9  7.614159e-10   \n",
      "4  ICC2k    Average random raters  0.997889  592.0    2    6  1.281778e-07   \n",
      "5  ICC3k     Average fixed raters  0.998311  592.0    2    6  1.281778e-07   \n",
      "\n",
      "         CI95%  \n",
      "0  [0.95, 1.0]  \n",
      "1  [0.95, 1.0]  \n",
      "2  [0.95, 1.0]  \n",
      "3  [0.99, 1.0]  \n",
      "4  [0.99, 1.0]  \n",
      "5  [0.99, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "data = {\n",
    "    'Image': [1, 2, 3],\n",
    "    'Ground Truth': [45, 32, 60],\n",
    "    'Model 1 Prediction': [44, 31, 59],\n",
    "    'Model 2 Prediction': [46, 33, 61],\n",
    "    'Model 3 Prediction': [43, 34, 62]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the data for ICC calculation\n",
    "df_melted = df.melt(id_vars='Image', var_name='Rater', value_name='Score')\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_melted, targets='Image', raters='Rater', ratings='Score')\n",
    "\n",
    "# Show ICC results\n",
    "print(icc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec117da5-bce8-43fb-beae-a630fe50096f",
   "metadata": {},
   "source": [
    "# read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3d5ec3-1b47-4789-ae6c-2b4f88cabe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "address= 'C:/Users/narges/PycharmProjects3/pythonProject3/IEEE_transaction_paper/all_methodology_comparings/'\n",
    "file_name= ['compare_local_maxima_real_synth_lightunet_unet.xlsx' , 'compare_cca_real_synth_unet_light_unet.xlsx' , 'compare_Watershed1_synth_real_unet_lightunet.xlsx']\n",
    "data_local_maxima= pd.read_excel(address+ file_name[0])\n",
    "data_cca= pd.read_excel(address+ file_name[1])\n",
    "data_watershed= pd.read_excel(address+ file_name[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc08bf-7cd5-4dc3-9cf8-30a34a739e62",
   "metadata": {},
   "source": [
    "# light unet real CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6136ae6d-b408-4f8f-aa1c-0256e6885362",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,0].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,1].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,4].dropna()\n",
    "model_cca =  data_cca.iloc[3:83,1].dropna()\n",
    "model_watershed = data_watershed.iloc[: , 14].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf5563e-bbcf-4339-8610-fde4061c2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (80,), (80,), (80,), (80,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape , model_cca.shape , model_watershed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635c7c61-7179-41c2-b21f-d0c8e9d2b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) ,\n",
    "    'model_2': list(model_cca),\n",
    "    'model_3':list( model_watershed)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf19cec2-2dcb-4371-b2ff-f6e16a213dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC           F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.956534   67.019668   73  148   \n",
      "1   ICC2     Single random raters  0.956918  173.745378   73  146   \n",
      "2   ICC3      Single fixed raters  0.982930  173.745378   73  146   \n",
      "3  ICC1k  Average raters absolute  0.985079   67.019668   73  148   \n",
      "4  ICC2k    Average random raters  0.985215  173.745378   73  146   \n",
      "5  ICC3k     Average fixed raters  0.994244  173.745378   73  146   \n",
      "\n",
      "            pval         CI95%  \n",
      "0   1.078487e-85  [0.94, 0.97]  \n",
      "1  4.204644e-114  [0.79, 0.98]  \n",
      "2  4.204644e-114  [0.98, 0.99]  \n",
      "3   1.078487e-85  [0.98, 0.99]  \n",
      "4  4.204644e-114  [0.92, 0.99]  \n",
      "5  4.204644e-114   [0.99, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(df, id_vars=[\"Image\", \"operator\"], value_vars=[\"model_1\", \"model_2\", \"model_3\"],\n",
    "                  var_name=\"model\", value_name=\"model_count\")\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_long, targets='operator', raters='model', ratings='model_count')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "454e16ed-cdab-467d-917f-38e0cadbf07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICC Results was saved.\n"
     ]
    }
   ],
   "source": [
    "icc_file = './ICC_results/icc_light_unet_realvssynth.csv'\n",
    "# Add ICC values into a new DataFrame\n",
    "icc_results = icc[[\"Type\", \"Description\", \"ICC\", \"F\", \"df1\", \"df2\", \"pval\", \"CI95%\"]].copy()\n",
    "\n",
    "# Save to a CSV or Excel file\n",
    "icc_results.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "print(\"\\nICC Results was saved.\")\n",
    "# print(icc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704c3c1-610b-4cf3-8537-01ab7255863e",
   "metadata": {},
   "source": [
    "# light unet synth CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d07fea9-9895-408f-af27-3fffde5d4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,6].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,7].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,10].dropna()\n",
    "model_cca =  data_cca.iloc[3:83,7].dropna()\n",
    "model_watershed = data_watershed.iloc[: , 6].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ff4996-b588-4a76-8550-2dadab185737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32,), (32,), (32,), (32,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape , model_cca.shape , model_watershed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f5011e-3edb-4e22-94df-3b848f9e45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) ,\n",
    "    'model_2': list(model_cca),\n",
    "    'model_3':list( model_watershed)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5932e21d-3451-4544-8993-ead4c62c6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC          F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.932442  42.406406   29   60   \n",
      "1   ICC2     Single random raters  0.933259  92.941543   29   58   \n",
      "2   ICC3      Single fixed raters  0.968402  92.941543   29   58   \n",
      "3  ICC1k  Average raters absolute  0.976419  42.406406   29   60   \n",
      "4  ICC2k    Average random raters  0.976717  92.941543   29   58   \n",
      "5  ICC3k     Average fixed raters  0.989241  92.941543   29   58   \n",
      "\n",
      "           pval         CI95%  \n",
      "0  3.745744e-30  [0.88, 0.96]  \n",
      "1  8.244729e-39  [0.74, 0.98]  \n",
      "2  8.244729e-39  [0.94, 0.98]  \n",
      "3  3.745744e-30  [0.96, 0.99]  \n",
      "4  8.244729e-39  [0.89, 0.99]  \n",
      "5  8.244729e-39  [0.98, 0.99]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(df, id_vars=[\"Image\", \"operator\"], value_vars=[\"model_1\", \"model_2\", \"model_3\"],\n",
    "                  var_name=\"model\", value_name=\"model_count\")\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_long, targets='operator', raters='model', ratings='model_count')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f05a38cd-5526-44be-b03d-b492866d934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated ICC Results DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if the file exists and append or create a new one\n",
    "import os\n",
    "if os.path.exists(icc_file):\n",
    "    # Load existing results\n",
    "    icc_existing = pd.read_csv(icc_file)\n",
    "    # Append new results\n",
    "    icc_combined = pd.concat([icc_existing, icc], ignore_index=True)\n",
    "else:\n",
    "    # If file doesn't exist, start with the new results\n",
    "    icc_combined = icc_new_results\n",
    "\n",
    "# Save the combined results back to the file\n",
    "icc_combined.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the combined DataFrame for verification\n",
    "print(\"\\nUpdated ICC Results DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e03b4-7e9d-489c-b7eb-393a1d18119c",
   "metadata": {},
   "source": [
    "# unet real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c84b301-c3a0-471d-b8b8-083c6a82dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,0].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,1].dropna()\n",
    "#          u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,2].dropna()\n",
    "model_cca =  data_cca.iloc[3:83,3].dropna()\n",
    "model_watershed = data_watershed.iloc[: , 10].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f127e6-9674-48d7-8c09-411dfff31e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (80,), (80,), (80,), (80,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape , model_cca.shape , model_watershed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17185aef-12e0-493b-9ede-bebbe665c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) ,\n",
    "    'model_2': list(model_cca),\n",
    "    'model_3':list( model_watershed)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9afed0b3-d678-4b9d-a129-7a98924b8689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC           F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.984689  193.942300   73  148   \n",
      "1   ICC2     Single random raters  0.984745  674.923714   73  146   \n",
      "2   ICC3      Single fixed raters  0.995568  674.923714   73  146   \n",
      "3  ICC1k  Average raters absolute  0.994844  193.942300   73  148   \n",
      "4  ICC2k    Average random raters  0.994863  674.923714   73  146   \n",
      "5  ICC3k     Average fixed raters  0.998518  674.923714   73  146   \n",
      "\n",
      "            pval         CI95%  \n",
      "0  6.347735e-119  [0.98, 0.99]  \n",
      "1  9.997866e-157  [0.88, 0.99]  \n",
      "2  9.997866e-157   [0.99, 1.0]  \n",
      "3  6.347735e-119   [0.99, 1.0]  \n",
      "4  9.997866e-157   [0.96, 1.0]  \n",
      "5  9.997866e-157    [1.0, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(df, id_vars=[\"Image\", \"operator\"], value_vars=[\"model_1\", \"model_2\", \"model_3\"],\n",
    "                  var_name=\"model\", value_name=\"model_count\")\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_long, targets='operator', raters='model', ratings='model_count')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59e83c88-b169-4d3a-a52c-cac294bba0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICC Results was saved.\n"
     ]
    }
   ],
   "source": [
    "icc_file = './ICC_results/icc_unet_realvssynth.csv'\n",
    "# Add ICC values into a new DataFrame\n",
    "icc_results = icc[[\"Type\", \"Description\", \"ICC\", \"F\", \"df1\", \"df2\", \"pval\", \"CI95%\"]].copy()\n",
    "\n",
    "# Save to a CSV or Excel file\n",
    "icc_results.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "print(\"\\nICC Results was saved.\")\n",
    "# print(icc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8612a-de53-4cfb-b24e-8327745961ff",
   "metadata": {},
   "source": [
    "# unet synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408ba03c-8971-4efe-a0d7-8805bc704483",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,6].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,7].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,8].dropna()\n",
    "model_cca =  data_cca.iloc[3:83,9].dropna()\n",
    "model_watershed = data_watershed.iloc[: , 2].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66295ec2-23a8-47eb-b5c3-f24303fe663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32,), (32,), (32,), (32,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape , model_cca.shape , model_watershed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c59ef8dc-bdd9-410a-96bd-40d09d904aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) ,\n",
    "    'model_2': list(model_cca),\n",
    "    'model_3':list( model_watershed)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60343d2f-7336-42f8-985a-43ed0d79ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC           F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.976331  124.750213   29   60   \n",
      "1   ICC2     Single random raters  0.976410  215.984516   29   58   \n",
      "2   ICC3      Single fixed raters  0.986238  215.984516   29   58   \n",
      "3  ICC1k  Average raters absolute  0.991984  124.750213   29   60   \n",
      "4  ICC2k    Average random raters  0.992011  215.984516   29   58   \n",
      "5  ICC3k     Average fixed raters  0.995370  215.984516   29   58   \n",
      "\n",
      "           pval         CI95%  \n",
      "0  1.253914e-43  [0.96, 0.99]  \n",
      "1  3.284291e-49  [0.92, 0.99]  \n",
      "2  3.284291e-49  [0.97, 0.99]  \n",
      "3  1.253914e-43   [0.99, 1.0]  \n",
      "4  3.284291e-49   [0.97, 1.0]  \n",
      "5  3.284291e-49   [0.99, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(df, id_vars=[\"Image\", \"operator\"], value_vars=[\"model_1\", \"model_2\", \"model_3\"],\n",
    "                  var_name=\"model\", value_name=\"model_count\")\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_long, targets='operator', raters='model', ratings='model_count')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "600eee77-8f74-4c3d-8759-fad3604999df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated ICC Results DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if the file exists and append or create a new one\n",
    "import os\n",
    "if os.path.exists(icc_file):\n",
    "    # Load existing results\n",
    "    icc_existing = pd.read_csv(icc_file)\n",
    "    # Append new results\n",
    "    icc_combined = pd.concat([icc_existing, icc], ignore_index=True)\n",
    "else:\n",
    "    # If file doesn't exist, start with the new results\n",
    "    icc_combined = icc_new_results\n",
    "\n",
    "# Save the combined results back to the file\n",
    "icc_combined.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the combined DataFrame for verification\n",
    "print(\"\\nUpdated ICC Results DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09e389-f16d-40bb-a3fb-bdbe2d538d9c",
   "metadata": {},
   "source": [
    "# Bland–Altman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004fa813-c7a7-4e82-9e6f-d0ad3ebb13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bland_altman_plot(manual_counts, model_predictions, title=\"Bland–Altman Plot\"):\n",
    "    \"\"\"\n",
    "    Generate a Bland–Altman plot and calculate bias with confidence intervals (CI95%).\n",
    "\n",
    "    Parameters:\n",
    "    - manual_counts: Array of manual counts (ground truth).\n",
    "    - model_predictions: Array of model predictions.\n",
    "    - title: Title of the plot.\n",
    "    \"\"\"\n",
    "    # Calculate mean and differences\n",
    "    avg = (manual_counts + model_predictions) / 2.0\n",
    "    diff = manual_counts - model_predictions\n",
    "    bias = np.mean(diff)\n",
    "    std_diff = np.std(diff, ddof=1)\n",
    "\n",
    "    # Calculate CI95% for bias\n",
    "    n = len(diff)\n",
    "    ci95_lower = bias - 1.96 * (std_diff / np.sqrt(n))\n",
    "    ci95_upper = bias + 1.96 * (std_diff / np.sqrt(n))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(avg, diff, color=\"blue\", alpha=0.6, label=\"Differences\")\n",
    "    plt.axhline(bias, color=\"red\", linestyle=\"--\", label=f\"Bias: {bias:.2f}\")\n",
    "    plt.axhline(ci95_lower, color=\"green\", linestyle=\"--\", label=f\"CI95%: [{ci95_lower:.2f}, {ci95_upper:.2f}]\")\n",
    "    plt.axhline(ci95_upper, color=\"green\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Average of Manual and Model Counts\")\n",
    "    plt.ylabel(\"Difference (Manual - Model)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Bias: {bias:.2f}\")\n",
    "    print(f\"CI95%: [{ci95_lower:.2f}, {ci95_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6f784-9c2e-438a-9de2-07d32bd1b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "# Replace these with your actual data\n",
    "manual_counts = np.array([100, 102, 98, 105, 110])  # Replace with real manual counts\n",
    "model_predictions = np.array([98, 101, 100, 106, 112])  # Replace with model predictions\n",
    "\n",
    "# Call the function for Bland–Altman analysis\n",
    "bland_altman_plot(manual_counts, model_predictions, title=\"Bland–Altman Plot for Light U-Net (Real Dataset)\")`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
