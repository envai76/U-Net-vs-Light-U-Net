{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be49f79b-442c-4509-912e-de320713eee3",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4badf27c-abfc-4189-a445-b5de4bedd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pingouin\n",
    "# !pip install openpyxl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from statsmodels.stats.weightstats import DescrStatsW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9892562-4780-46aa-b8a7-bc32d77e149a",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375cab04-f8a8-4538-88ce-bc5f107eb5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC      F  df1  df2          pval  \\\n",
      "0   ICC1   Single raters absolute  0.991607  473.6    2    9  7.614159e-10   \n",
      "1   ICC2     Single random raters  0.991611  592.0    2    6  1.281778e-07   \n",
      "2   ICC3      Single fixed raters  0.993277  592.0    2    6  1.281778e-07   \n",
      "3  ICC1k  Average raters absolute  0.997889  473.6    2    9  7.614159e-10   \n",
      "4  ICC2k    Average random raters  0.997889  592.0    2    6  1.281778e-07   \n",
      "5  ICC3k     Average fixed raters  0.998311  592.0    2    6  1.281778e-07   \n",
      "\n",
      "         CI95%  \n",
      "0  [0.95, 1.0]  \n",
      "1  [0.95, 1.0]  \n",
      "2  [0.95, 1.0]  \n",
      "3  [0.99, 1.0]  \n",
      "4  [0.99, 1.0]  \n",
      "5  [0.99, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "data = {\n",
    "    'Image': [1, 2, 3],\n",
    "    'Ground Truth': [45, 32, 60],\n",
    "    'Model 1 Prediction': [44, 31, 59],\n",
    "    'Model 2 Prediction': [46, 33, 61],\n",
    "    'Model 3 Prediction': [43, 34, 62]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the data for ICC calculation\n",
    "df_melted = df.melt(id_vars='Image', var_name='Rater', value_name='Score')\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_melted, targets='Image', raters='Rater', ratings='Score')\n",
    "\n",
    "# Show ICC results\n",
    "print(icc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec117da5-bce8-43fb-beae-a630fe50096f",
   "metadata": {},
   "source": [
    "# read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3d5ec3-1b47-4789-ae6c-2b4f88cabe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "address= 'C:/Users/narges/PycharmProjects3/pythonProject3/IEEE_transaction_paper/all_methodology_comparings/'\n",
    "file_name= ['compare_local_maxima_real_synth_lightunet_unet.xlsx' , 'compare_cca_real_synth_unet_light_unet.xlsx' , 'compare_Watershed1_synth_real_unet_lightunet.xlsx']\n",
    "data_local_maxima= pd.read_excel(address+ file_name[0])\n",
    "data_cca= pd.read_excel(address+ file_name[1])\n",
    "data_watershed= pd.read_excel(address+ file_name[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc08bf-7cd5-4dc3-9cf8-30a34a739e62",
   "metadata": {},
   "source": [
    "# light unet real CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6136ae6d-b408-4f8f-aa1c-0256e6885362",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,0].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,1].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,4].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf5563e-bbcf-4339-8610-fde4061c2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (80,), (80,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635c7c61-7179-41c2-b21f-d0c8e9d2b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a59d74-66f1-42b1-a9ac-88a5627eca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reshape the dataframe into a long format\n",
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['Image'],            # Keeps the 'Image' column as is (the targets)\n",
    "    var_name='Rater',             # Creates a new column to distinguish 'ground_truth' and 'model_1'\n",
    "    value_name='Score'            # Contains the actual numeric values (manual counts or model predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0356e0a-452b-4464-93fa-7e4be90939ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Rater</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_</td>\n",
       "      <td>operator</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_</td>\n",
       "      <td>operator</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003_</td>\n",
       "      <td>operator</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_</td>\n",
       "      <td>operator</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_</td>\n",
       "      <td>operator</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>076_</td>\n",
       "      <td>model_1</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>077_</td>\n",
       "      <td>model_1</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>078_</td>\n",
       "      <td>model_1</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>079_</td>\n",
       "      <td>model_1</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>080_</td>\n",
       "      <td>model_1</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image     Rater  Score\n",
       "0    001_  operator    414\n",
       "1    002_  operator    397\n",
       "2    003_  operator    356\n",
       "3    004_  operator    297\n",
       "4    005_  operator    309\n",
       "..    ...       ...    ...\n",
       "155  076_   model_1    361\n",
       "156  077_   model_1    421\n",
       "157  078_   model_1    343\n",
       "158  079_   model_1    393\n",
       "159  080_   model_1    422\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf19cec2-2dcb-4371-b2ff-f6e16a213dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC          F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.945497  35.695332   79   80   \n",
      "1   ICC2     Single random raters  0.945491  35.546489   79   79   \n",
      "2   ICC3      Single fixed raters  0.945275  35.546489   79   79   \n",
      "3  ICC1k  Average raters absolute  0.971985  35.695332   79   80   \n",
      "4  ICC2k    Average random raters  0.971982  35.546489   79   79   \n",
      "5  ICC3k     Average fixed raters  0.971868  35.546489   79   79   \n",
      "\n",
      "           pval         CI95%  \n",
      "0  5.621980e-41  [0.92, 0.96]  \n",
      "1  1.768316e-40  [0.92, 0.96]  \n",
      "2  1.768316e-40  [0.92, 0.96]  \n",
      "3  5.621980e-41  [0.96, 0.98]  \n",
      "4  1.768316e-40  [0.96, 0.98]  \n",
      "5  1.768316e-40  [0.96, 0.98]  \n"
     ]
    }
   ],
   "source": [
    "icc = pg.intraclass_corr(data=df_long, targets='Image', raters='Rater', ratings='Score')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454e16ed-cdab-467d-917f-38e0cadbf07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICC Results was saved.\n"
     ]
    }
   ],
   "source": [
    "icc_file = './ICC_results/icc_best_light_unet_realvssynth.csv'\n",
    "# Add ICC values into a new DataFrame\n",
    "icc_results = icc[[\"Type\", \"Description\", \"ICC\", \"F\", \"df1\", \"df2\", \"pval\", \"CI95%\"]].copy()\n",
    "\n",
    "# Save to a CSV or Excel file\n",
    "icc_results.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "print(\"\\nICC Results was saved.\")\n",
    "# print(icc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704c3c1-610b-4cf3-8537-01ab7255863e",
   "metadata": {},
   "source": [
    "# light unet synth CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d07fea9-9895-408f-af27-3fffde5d4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,6].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,7].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,10].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ff4996-b588-4a76-8550-2dadab185737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32,), (32,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23f5011e-3edb-4e22-94df-3b848f9e45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5932e21d-3451-4544-8993-ead4c62c6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC          F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.785789   8.336605   31   32   \n",
      "1   ICC2     Single random raters  0.801648  32.882025   31   31   \n",
      "2   ICC3      Single fixed raters  0.940972  32.882025   31   31   \n",
      "3  ICC1k  Average raters absolute  0.880047   8.336605   31   32   \n",
      "4  ICC2k    Average random raters  0.889905  32.882025   31   31   \n",
      "5  ICC3k     Average fixed raters  0.969588  32.882025   31   31   \n",
      "\n",
      "           pval          CI95%  \n",
      "0  2.034298e-08   [0.61, 0.89]  \n",
      "1  1.959750e-16  [-0.05, 0.95]  \n",
      "2  1.959750e-16   [0.88, 0.97]  \n",
      "3  2.034298e-08   [0.76, 0.94]  \n",
      "4  1.959750e-16  [-0.09, 0.97]  \n",
      "5  1.959750e-16   [0.94, 0.99]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['Image'],            # Keeps the 'Image' column as is (the targets)\n",
    "    var_name='Rater',             # Creates a new column to distinguish 'ground_truth' and 'model_1'\n",
    "    value_name='Score'            # Contains the actual numeric values (manual counts or model predictions)\n",
    ")\n",
    "icc = pg.intraclass_corr(data=df_long, targets='Image', raters='Rater', ratings='Score')\n",
    "print(icc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f05a38cd-5526-44be-b03d-b492866d934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated ICC Results DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if the file exists and append or create a new one\n",
    "import os\n",
    "if os.path.exists(icc_file):\n",
    "    # Load existing results\n",
    "    icc_existing = pd.read_csv(icc_file)\n",
    "    # Append new results\n",
    "    icc_combined = pd.concat([icc_existing, icc], ignore_index=True)\n",
    "else:\n",
    "    # If file doesn't exist, start with the new results\n",
    "    icc_combined = icc_new_results\n",
    "\n",
    "# Save the combined results back to the file\n",
    "icc_combined.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the combined DataFrame for verification\n",
    "print(\"\\nUpdated ICC Results DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e03b4-7e9d-489c-b7eb-393a1d18119c",
   "metadata": {},
   "source": [
    "# unet real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c84b301-c3a0-471d-b8b8-083c6a82dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,0].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,1].dropna()\n",
    "#          u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,2].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14f127e6-9674-48d7-8c09-411dfff31e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (80,), (80,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17185aef-12e0-493b-9ede-bebbe665c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) ,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9afed0b3-d678-4b9d-a129-7a98924b8689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC          F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.811091   9.587121   79   80   \n",
      "1   ICC2     Single random raters  0.820960  23.021915   79   79   \n",
      "2   ICC3      Single fixed raters  0.916743  23.021915   79   79   \n",
      "3  ICC1k  Average raters absolute  0.895693   9.587121   79   80   \n",
      "4  ICC2k    Average random raters  0.901678  23.021915   79   79   \n",
      "5  ICC3k     Average fixed raters  0.956563  23.021915   79   79   \n",
      "\n",
      "           pval         CI95%  \n",
      "0  1.414661e-20  [0.72, 0.87]  \n",
      "1  1.604785e-33  [0.14, 0.94]  \n",
      "2  1.604785e-33  [0.87, 0.95]  \n",
      "3  1.414661e-20  [0.84, 0.93]  \n",
      "4  1.604785e-33  [0.25, 0.97]  \n",
      "5  1.604785e-33  [0.93, 0.97]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, calculate ICC for each model compared to the operator\n",
    "# Use a long format, where each row is a single sample/model comparison\n",
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['Image'],            # Keeps the 'Image' column as is (the targets)\n",
    "    var_name='Rater',             # Creates a new column to distinguish 'ground_truth' and 'model_1'\n",
    "    value_name='Score'            # Contains the actual numeric values (manual counts or model predictions)\n",
    ")\n",
    "icc = pg.intraclass_corr(data=df_long, targets='Image', raters='Rater', ratings='Score')\n",
    "print(icc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59e83c88-b169-4d3a-a52c-cac294bba0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICC Results was saved.\n"
     ]
    }
   ],
   "source": [
    "icc_file = './ICC_results/icc_best_unet_realvssynth.csv'\n",
    "# Add ICC values into a new DataFrame\n",
    "icc_results = icc[[\"Type\", \"Description\", \"ICC\", \"F\", \"df1\", \"df2\", \"pval\", \"CI95%\"]].copy()\n",
    "\n",
    "# Save to a CSV or Excel file\n",
    "icc_results.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the DataFrame for verification\n",
    "print(\"\\nICC Results was saved.\")\n",
    "# print(icc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8612a-de53-4cfb-b24e-8327745961ff",
   "metadata": {},
   "source": [
    "# unet synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "408ba03c-8971-4efe-a0d7-8805bc704483",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name= data_local_maxima.iloc[1:,6].dropna()\n",
    "ground_truths=data_local_maxima.iloc[1:,7].dropna()\n",
    "#          light-u-net lm cca watershed\n",
    "model_lm =  data_local_maxima.iloc[1:,8].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66295ec2-23a8-47eb-b5c3-f24303fe663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), (32,), (32,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_name.shape , ground_truths.shape , model_lm.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c59ef8dc-bdd9-410a-96bd-40d09d904aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Image': list(images_name),\n",
    "    'operator':list(ground_truths),\n",
    "    'model_1':list( model_lm) \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60343d2f-7336-42f8-985a-43ed0d79ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['Image'],            # Keeps the 'Image' column as is (the targets)\n",
    "    var_name='Rater',             # Creates a new column to distinguish 'ground_truth' and 'model_1'\n",
    "    value_name='Score'            # Contains the actual numeric values (manual counts or model predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b9d64f0-ad81-47c2-987e-fec1601f589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type              Description       ICC          F  df1  df2  \\\n",
      "0   ICC1   Single raters absolute  0.770692   7.721875   31   32   \n",
      "1   ICC2     Single random raters  0.788713  30.153089   31   31   \n",
      "2   ICC3      Single fixed raters  0.935801  30.153089   31   31   \n",
      "3  ICC1k  Average raters absolute  0.870498   7.721875   31   32   \n",
      "4  ICC2k    Average random raters  0.881877  30.153089   31   31   \n",
      "5  ICC3k     Average fixed raters  0.966836  30.153089   31   31   \n",
      "\n",
      "           pval          CI95%  \n",
      "0  5.357636e-08   [0.58, 0.88]  \n",
      "1  6.945973e-16  [-0.05, 0.94]  \n",
      "2  6.945973e-16   [0.87, 0.97]  \n",
      "3  5.357636e-08   [0.74, 0.94]  \n",
      "4  6.945973e-16   [-0.1, 0.97]  \n",
      "5  6.945973e-16   [0.93, 0.98]  \n"
     ]
    }
   ],
   "source": [
    "icc = pg.intraclass_corr(data=df_long, targets='Image', raters='Rater', ratings='Score')\n",
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "600eee77-8f74-4c3d-8759-fad3604999df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated ICC Results DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if the file exists and append or create a new one\n",
    "import os\n",
    "if os.path.exists(icc_file):\n",
    "    # Load existing results\n",
    "    icc_existing = pd.read_csv(icc_file)\n",
    "    # Append new results\n",
    "    icc_combined = pd.concat([icc_existing, icc], ignore_index=True)\n",
    "else:\n",
    "    # If file doesn't exist, start with the new results\n",
    "    icc_combined = icc_new_results\n",
    "\n",
    "# Save the combined results back to the file\n",
    "icc_combined.to_csv(icc_file, index=False)\n",
    "\n",
    "# Print the combined DataFrame for verification\n",
    "print(\"\\nUpdated ICC Results DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09e389-f16d-40bb-a3fb-bdbe2d538d9c",
   "metadata": {},
   "source": [
    "# Bland–Altman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004fa813-c7a7-4e82-9e6f-d0ad3ebb13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bland_altman_plot(manual_counts, model_predictions, title=\"Bland–Altman Plot\"):\n",
    "    \"\"\"\n",
    "    Generate a Bland–Altman plot and calculate bias with confidence intervals (CI95%).\n",
    "\n",
    "    Parameters:\n",
    "    - manual_counts: Array of manual counts (ground truth).\n",
    "    - model_predictions: Array of model predictions.\n",
    "    - title: Title of the plot.\n",
    "    \"\"\"\n",
    "    # Calculate mean and differences\n",
    "    avg = (manual_counts + model_predictions) / 2.0\n",
    "    diff = manual_counts - model_predictions\n",
    "    bias = np.mean(diff)\n",
    "    std_diff = np.std(diff, ddof=1)\n",
    "\n",
    "    # Calculate CI95% for bias\n",
    "    n = len(diff)\n",
    "    ci95_lower = bias - 1.96 * (std_diff / np.sqrt(n))\n",
    "    ci95_upper = bias + 1.96 * (std_diff / np.sqrt(n))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(avg, diff, color=\"blue\", alpha=0.6, label=\"Differences\")\n",
    "    plt.axhline(bias, color=\"red\", linestyle=\"--\", label=f\"Bias: {bias:.2f}\")\n",
    "    plt.axhline(ci95_lower, color=\"green\", linestyle=\"--\", label=f\"CI95%: [{ci95_lower:.2f}, {ci95_upper:.2f}]\")\n",
    "    plt.axhline(ci95_upper, color=\"green\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Average of Manual and Model Counts\")\n",
    "    plt.ylabel(\"Difference (Manual - Model)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Bias: {bias:.2f}\")\n",
    "    print(f\"CI95%: [{ci95_lower:.2f}, {ci95_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6f784-9c2e-438a-9de2-07d32bd1b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "# Replace these with your actual data\n",
    "manual_counts = np.array([100, 102, 98, 105, 110])  # Replace with real manual counts\n",
    "model_predictions = np.array([98, 101, 100, 106, 112])  # Replace with model predictions\n",
    "\n",
    "# Call the function for Bland–Altman analysis\n",
    "bland_altman_plot(manual_counts, model_predictions, title=\"Bland–Altman Plot for Light U-Net (Real Dataset)\")`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
